{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:49:06.042735Z",
     "iopub.status.busy": "2021-06-29T11:49:06.042396Z",
     "iopub.status.idle": "2021-06-29T11:49:06.048714Z",
     "shell.execute_reply": "2021-06-29T11:49:06.047959Z",
     "shell.execute_reply.started": "2021-06-29T11:49:06.04268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp38-cp38-win_amd64.whl (12.5 MB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp38-cp38-win_amd64.whl (483 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp38-cp38-win_amd64.whl (39 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp38-cp38-win_amd64.whl (122 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.17.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp38-cp38-win_amd64.whl (25 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Downloading thinc-8.2.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.10.0,>=0.3.0->spacy) (0.4.4)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: colorama, catalogue, srsly, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, cloudpathlib, blis, weasel, thinc, spacy-loggers, spacy-legacy, langcodes, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.3 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.7.4 requires astroid<2.7,>=2.5.2, but you have astroid 2.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:07:03.822600Z",
     "iopub.status.busy": "2021-06-30T19:07:03.822370Z",
     "iopub.status.idle": "2021-06-30T19:07:03.828487Z",
     "shell.execute_reply": "2021-06-30T19:07:03.827848Z",
     "shell.execute_reply.started": "2021-06-30T19:07:03.822557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.59.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.25.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.10.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.17.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.0.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:07:03.829922Z",
     "iopub.status.busy": "2021-06-30T19:07:03.829662Z",
     "iopub.status.idle": "2021-06-30T19:07:03.835332Z",
     "shell.execute_reply": "2021-06-30T19:07:03.833907Z",
     "shell.execute_reply.started": "2021-06-30T19:07:03.829874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\u001b[2K\u001b[38;5;2m[+] Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.7.2) =================\u001b[0m\n",
      "\u001b[38;5;4m[i] spaCy installation:\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\spacy\u001b[0m\n",
      "\n",
      "NAME             SPACY            VERSION                              \n",
      "en_core_web_sm   >=3.7.0,<3.8.0   \u001b[38;5;2m3.7.0\u001b[0m   \u001b[38;5;2m[+]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    " !python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:07:03.837477Z",
     "iopub.status.busy": "2021-06-30T19:07:03.836818Z",
     "iopub.status.idle": "2021-06-30T19:07:04.473768Z",
     "shell.execute_reply": "2021-06-30T19:07:04.472909Z",
     "shell.execute_reply.started": "2021-06-30T19:07:03.837225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the installed model \"en_core_web_sm\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents, tokens and spans\n",
    "### Processing text\n",
    "\n",
    "Processing text with the `nlp` object returns a `Doc` object that holds all information about the tokens, their linguistic features and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-30T19:08:22.720487Z",
     "iopub.status.busy": "2021-06-30T19:08:22.720190Z",
     "iopub.status.idle": "2021-06-30T19:08:22.743760Z",
     "shell.execute_reply": "2021-06-30T19:08:22.743119Z",
     "shell.execute_reply.started": "2021-06-30T19:08:22.720435Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a example text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "### The English language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:08:25.444672Z",
     "iopub.status.busy": "2021-06-30T19:08:25.444373Z",
     "iopub.status.idle": "2021-06-30T19:08:25.530091Z",
     "shell.execute_reply": "2021-06-30T19:08:25.529072Z",
     "shell.execute_reply.started": "2021-06-30T19:08:25.444619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress to Contributor to make your voice count!\n"
     ]
    }
   ],
   "source": [
    "# Import the English language class\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = English()\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"Progress to Contributor to make your voice count!\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The German language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:08:52.185478Z",
     "iopub.status.busy": "2021-06-30T19:08:52.185175Z",
     "iopub.status.idle": "2021-06-30T19:08:52.485469Z",
     "shell.execute_reply": "2021-06-30T19:08:52.484810Z",
     "shell.execute_reply.started": "2021-06-30T19:08:52.185428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n"
     ]
    }
   ],
   "source": [
    "# Import the German language class\n",
    "from spacy.lang.de import German\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = German()\n",
    "\n",
    "# Process a text (this is German for: \"Kind regards!\")\n",
    "doc = nlp(\"Liebe Grüße!\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Spanish language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:08:54.175311Z",
     "iopub.status.busy": "2021-06-30T19:08:54.174988Z",
     "iopub.status.idle": "2021-06-30T19:08:54.540279Z",
     "shell.execute_reply": "2021-06-30T19:08:54.539463Z",
     "shell.execute_reply.started": "2021-06-30T19:08:54.175258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# Import the Spanish language class\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = Spanish()\n",
    "\n",
    "# Process a text (this is Spanish for: \"How are you?\")\n",
    "doc = nlp(\"¿Cómo estás?\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Tokenization\n",
    "\n",
    "`SpaCy` automatically divides your document into tokens when you use a `for-loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:11:06.439276Z",
     "iopub.status.busy": "2021-06-30T19:11:06.438964Z",
     "iopub.status.idle": "2021-06-30T19:11:06.523155Z",
     "shell.execute_reply": "2021-06-30T19:11:06.521952Z",
     "shell.execute_reply.started": "2021-06-30T19:11:06.439225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "# Import the English language class and create the nlp object\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "# Print the first token's text\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:11:10.915114Z",
     "iopub.status.busy": "2021-06-30T19:11:10.914822Z",
     "iopub.status.idle": "2021-06-30T19:11:10.921322Z",
     "shell.execute_reply": "2021-06-30T19:11:10.920349Z",
     "shell.execute_reply.started": "2021-06-30T19:11:10.915065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "like\n",
      "tree\n",
      "kangaroos\n",
      "and\n",
      "narwhals\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spans\n",
    "### Accessing spans\n",
    "\n",
    "Span indices are exclusive. So `doc[2:5]` is a span starting at token 2, up to – but not including! – token 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:11:35.725152Z",
     "iopub.status.busy": "2021-06-30T19:11:35.724790Z",
     "iopub.status.idle": "2021-06-30T19:11:35.730883Z",
     "shell.execute_reply": "2021-06-30T19:11:35.730144Z",
     "shell.execute_reply.started": "2021-06-30T19:11:35.725102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n"
     ]
    }
   ],
   "source": [
    "span = doc[2:4]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:51:20.094203Z",
     "iopub.status.busy": "2021-06-29T11:51:20.093647Z",
     "iopub.status.idle": "2021-06-29T11:51:20.18873Z",
     "shell.execute_reply": "2021-06-29T11:51:20.187989Z",
     "shell.execute_reply.started": "2021-06-29T11:51:20.094008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n",
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Import the English language class and create the nlp object\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a span manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:51:29.848494Z",
     "iopub.status.busy": "2021-06-29T11:51:29.84819Z",
     "iopub.status.idle": "2021-06-29T11:51:29.856391Z",
     "shell.execute_reply": "2021-06-29T11:51:29.855463Z",
     "shell.execute_reply.started": "2021-06-29T11:51:29.848445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guwahati Assam'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Span object\n",
    "from spacy.tokens import Span\n",
    "# Create a Doc object\n",
    "doc = nlp(\"I live in Guwahati Assam\")\n",
    "# Span for \"Guwahati\" with label GPE (geopolitical)\n",
    "span = Span(doc, 3, 5, label=\"GPE\")\n",
    "span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:12:19.359551Z",
     "iopub.status.busy": "2021-06-30T19:12:19.359257Z",
     "iopub.status.idle": "2021-06-30T19:12:19.367765Z",
     "shell.execute_reply": "2021-06-30T19:12:19.366945Z",
     "shell.execute_reply.started": "2021-06-30T19:12:19.359497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. Now less than 4% are.\")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals '%'\n",
    "        if next_token.text == '%':\n",
    "            print('Percentage found:', token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic features\n",
    "\n",
    "Attributes return label IDs. For string labels, use the attributes with an underscore. For example, `token.pos_`.\n",
    "\n",
    "### POS-tagging and Lemmatization\n",
    "\n",
    "You can establish the `lemma` for each `token` as well as its `part of speech`. Use the `token.lemma_` method for lemmas and the `token.pos_` method for parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:14:40.175502Z",
     "iopub.status.busy": "2021-06-30T19:14:40.175201Z",
     "iopub.status.idle": "2021-06-30T19:14:40.439913Z",
     "shell.execute_reply": "2021-06-30T19:14:40.438855Z",
     "shell.execute_reply.started": "2021-06-30T19:14:40.175452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET', 'VERB', 'DET', 'DET', 'NOUN', 'NOUN', 'PUNCT']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is an another example text.\")\n",
    "# Coarse-grained part-of-speech tags\n",
    "[token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:14:44.259465Z",
     "iopub.status.busy": "2021-06-30T19:14:44.259180Z",
     "iopub.status.idle": "2021-06-30T19:14:44.264854Z",
     "shell.execute_reply": "2021-06-30T19:14:44.264169Z",
     "shell.execute_reply.started": "2021-06-30T19:14:44.259415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'VBZ', 'DT', 'DT', 'NN', 'NN', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-grained part-of-speech tags\n",
    "[token.tag_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:15:26.420388Z",
     "iopub.status.busy": "2021-06-30T19:15:26.420103Z",
     "iopub.status.idle": "2021-06-30T19:15:26.440759Z",
     "shell.execute_reply": "2021-06-30T19:15:26.439553Z",
     "shell.execute_reply.started": "2021-06-30T19:15:26.420342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft – Microsoft – PROPN\n",
      "News – News – PROPN\n",
      "delivers – deliver – VERB\n",
      "news – news – NOUN\n",
      "from – from – ADP\n",
      "the – the – DET\n",
      "most – most – ADV\n",
      "popular – popular – ADJ\n",
      "and – and – CCONJ\n",
      "trusted – trusted – ADJ\n",
      "publishers – publisher – NOUN\n",
      ". – . – PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Microsoft News delivers news from the most popular and trusted publishers.\")\n",
    "for i in doc:\n",
    "    print(\"{0} – {1} – {2}\".format(i.text, i.lemma_, i.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic dependencies (predicted by statistical model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:15:51.536676Z",
     "iopub.status.busy": "2021-06-30T19:15:51.536325Z",
     "iopub.status.idle": "2021-06-30T19:15:51.566448Z",
     "shell.execute_reply": "2021-06-30T19:15:51.565616Z",
     "shell.execute_reply.started": "2021-06-30T19:15:51.536618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsubj', 'ROOT', 'det', 'amod', 'compound', 'attr', 'punct']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"This is a simple text example.\")\n",
    "# Dependency labels\n",
    "[token.dep_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:16:00.685376Z",
     "iopub.status.busy": "2021-06-30T19:16:00.685077Z",
     "iopub.status.idle": "2021-06-30T19:16:00.690506Z",
     "shell.execute_reply": "2021-06-30T19:16:00.689785Z",
     "shell.execute_reply.started": "2021-06-30T19:16:00.685321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'is', 'example', 'example', 'example', 'is', 'is']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntactic head token (governor)\n",
    "[token.head.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "\n",
    "A named entity is an object of the real world, for example, a person, an organization, etc. `SpaCy` can recognize different named entities in a document by forecasting it with the help of a built-in model. The standard way of named entity recognition (NER) is `doc.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:17:27.620843Z",
     "iopub.status.busy": "2021-06-30T19:17:27.620502Z",
     "iopub.status.idle": "2021-06-30T19:17:27.649137Z",
     "shell.execute_reply": "2021-06-30T19:17:27.648371Z",
     "shell.execute_reply.started": "2021-06-30T19:17:27.620794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Steve Jobs', 'PERSON'), ('Apple', 'ORG')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Steve Jobs founded Apple\")\n",
    "# Text and label of named entity span\n",
    "[(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:18:52.800524Z",
     "iopub.status.busy": "2021-06-30T19:18:52.800228Z",
     "iopub.status.idle": "2021-06-30T19:18:52.820169Z",
     "shell.execute_reply": "2021-06-30T19:18:52.819308Z",
     "shell.execute_reply.started": "2021-06-30T19:18:52.800474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ==== ORG\n",
      "first ==== ORDINAL\n",
      "U.S. ==== GPE\n",
      "$1 trillion ==== MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\")\n",
    "for i in doc.ents:\n",
    "    print(i.text + ' ==== ' + i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:19:31.365359Z",
     "iopub.status.busy": "2021-06-30T19:19:31.365034Z",
     "iopub.status.idle": "2021-06-30T19:19:31.386823Z",
     "shell.execute_reply": "2021-06-30T19:19:31.384752Z",
     "shell.execute_reply.started": "2021-06-30T19:19:31.365307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "’s          PROPN     ROOT      \n",
      "official    NOUN      acomp     \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          VERB      ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print('{:<12}{:<10}{:<10}'.format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:19:50.389507Z",
     "iopub.status.busy": "2021-06-30T19:19:50.389218Z",
     "iopub.status.idle": "2021-06-30T19:19:50.408633Z",
     "shell.execute_reply": "2021-06-30T19:19:50.407663Z",
     "shell.execute_reply.started": "2021-06-30T19:19:50.389457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:20:01.024470Z",
     "iopub.status.busy": "2021-06-30T19:20:01.024181Z",
     "iopub.status.idle": "2021-06-30T19:20:01.043903Z",
     "shell.execute_reply": "2021-06-30T19:20:01.042883Z",
     "shell.execute_reply.started": "2021-06-30T19:20:01.024422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print('Missing entity:', iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences (usually needs the dependency parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:20:58.901487Z",
     "iopub.status.busy": "2021-06-30T19:20:58.901191Z",
     "iopub.status.idle": "2021-06-30T19:20:58.920685Z",
     "shell.execute_reply": "2021-06-30T19:20:58.919792Z",
     "shell.execute_reply.started": "2021-06-30T19:20:58.901440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This a sentence.', 'This is another one.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"This a sentence. This is another one.\")\n",
    "# doc.sents is a generator that yields sentence spans\n",
    "[sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base noun phrases (needs the tagger and parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:21:11.181516Z",
     "iopub.status.busy": "2021-06-30T19:21:11.181174Z",
     "iopub.status.idle": "2021-06-30T19:21:11.202631Z",
     "shell.execute_reply": "2021-06-30T19:21:11.201354Z",
     "shell.execute_reply.started": "2021-06-30T19:21:11.181466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'a brown car']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"I have a brown car\")\n",
    "# doc.noun_chunks is a generator that yields spans\n",
    "[chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:21:19.035495Z",
     "iopub.status.busy": "2021-06-30T19:21:19.035201Z",
     "iopub.status.idle": "2021-06-30T19:21:19.040971Z",
     "shell.execute_reply": "2021-06-30T19:21:19.040224Z",
     "shell.execute_reply.started": "2021-06-30T19:21:19.035446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, singular or mass'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:21:21.819739Z",
     "iopub.status.busy": "2021-06-30T19:21:21.819441Z",
     "iopub.status.idle": "2021-06-30T19:21:21.824827Z",
     "shell.execute_reply": "2021-06-30T19:21:21.824116Z",
     "shell.execute_reply.started": "2021-06-30T19:21:21.819683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:21:35.434738Z",
     "iopub.status.busy": "2021-06-30T19:21:35.434451Z",
     "iopub.status.idle": "2021-06-30T19:21:35.438355Z",
     "shell.execute_reply": "2021-06-30T19:21:35.437541Z",
     "shell.execute_reply.started": "2021-06-30T19:21:35.434692Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T19:21:38.654698Z",
     "iopub.status.busy": "2021-06-30T19:21:38.654412Z",
     "iopub.status.idle": "2021-06-30T19:21:38.678161Z",
     "shell.execute_reply": "2021-06-30T19:21:38.676973Z",
     "shell.execute_reply.started": "2021-06-30T19:21:38.654650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0a82aff61e454220a2049886f8295e05-0\" class=\"displacy\" width=\"925\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">live</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Guwahati,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Assam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a82aff61e454220a2049886f8295e05-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a82aff61e454220a2049886f8295e05-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a82aff61e454220a2049886f8295e05-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a82aff61e454220a2049886f8295e05-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a82aff61e454220a2049886f8295e05-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a82aff61e454220a2049886f8295e05-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a82aff61e454220a2049886f8295e05-0-3\" stroke-width=\"2px\" d=\"M595,89.5 C595,2.0 750.0,2.0 750.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a82aff61e454220a2049886f8295e05-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,91.5 L758.0,79.5 742.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I live in Guwahati, Assam\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:26.404516Z",
     "iopub.status.busy": "2021-06-29T11:52:26.404237Z",
     "iopub.status.idle": "2021-06-29T11:52:26.427314Z",
     "shell.execute_reply": "2021-06-29T11:52:26.426524Z",
     "shell.execute_reply.started": "2021-06-29T11:52:26.404468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Bill Gates\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " founded \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Bill Gates founded Microsoft\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:29.716218Z",
     "iopub.status.busy": "2021-06-29T11:52:29.715889Z",
     "iopub.status.idle": "2021-06-29T11:52:29.893341Z",
     "shell.execute_reply": "2021-06-29T11:52:29.892257Z",
     "shell.execute_reply.started": "2021-06-29T11:52:29.716168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9494252318410429"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"I like cats\")\n",
    "doc2 = nlp(\"I like dogs\")\n",
    "# Compare 2 documents\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:33.087595Z",
     "iopub.status.busy": "2021-06-29T11:52:33.087299Z",
     "iopub.status.idle": "2021-06-29T11:52:33.106758Z",
     "shell.execute_reply": "2021-06-29T11:52:33.105318Z",
     "shell.execute_reply.started": "2021-06-29T11:52:33.087543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85979897"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare 2 tokens\n",
    "doc1[2].similarity(doc2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:38.344505Z",
     "iopub.status.busy": "2021-06-29T11:52:38.344228Z",
     "iopub.status.idle": "2021-06-29T11:52:38.366513Z",
     "shell.execute_reply": "2021-06-29T11:52:38.363032Z",
     "shell.execute_reply.started": "2021-06-29T11:52:38.344459Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.055946935"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare tokens and spans\n",
    "doc1[0].similarity(doc2[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:58.2464Z",
     "iopub.status.busy": "2021-06-29T11:52:58.246114Z",
     "iopub.status.idle": "2021-06-29T11:52:58.266758Z",
     "shell.execute_reply": "2021-06-29T11:52:58.266093Z",
     "shell.execute_reply.started": "2021-06-29T11:52:58.246353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.612486  , -0.00959456,  0.9075469 , -3.7867062 ,  2.4655213 ,\n",
       "        0.13715684,  2.4155567 , -2.5730793 , -2.867982  ,  3.2525606 ,\n",
       "       -1.2344294 ,  1.8056613 , -1.9664278 , -0.7356216 , -2.7180357 ,\n",
       "       -0.6440704 , -2.8764105 ,  3.0591764 , -1.2157367 ,  1.2292783 ,\n",
       "       -3.8869352 ,  1.5334756 , -0.42812008, -1.6634891 , -0.71992075,\n",
       "       -0.9405132 , -0.92217237,  1.4494174 ,  0.8063313 , -1.9848629 ,\n",
       "        1.463424  , -4.440749  , -2.0363843 ,  1.969531  ,  2.132836  ,\n",
       "       -0.06996736,  1.0586739 ,  0.72142375, -2.455808  ,  0.6979033 ,\n",
       "       -3.979558  ,  5.9907084 ,  0.46196795, -1.6138006 ,  6.1429152 ,\n",
       "       -0.6601538 ,  0.05084178, -1.2918823 , -0.60123396,  0.5269669 ,\n",
       "       -3.8541064 ,  1.5263548 ,  0.60274506, -0.57671547,  0.90186244,\n",
       "        1.1323965 , -0.22235966,  0.38049865, -0.29168057,  2.2304847 ,\n",
       "       -2.0556376 ,  4.193283  ,  4.0678716 , -1.9232148 ,  1.2723014 ,\n",
       "        8.359107  , -1.0821431 ,  3.8314052 , -1.5646377 ,  2.1246529 ,\n",
       "       -2.9685535 , -2.9034722 ,  3.0246754 , -0.0359354 , -0.882882  ,\n",
       "       -1.0055529 ,  1.2224728 , -2.6909702 , -4.7067666 ,  0.38048625,\n",
       "       -1.3316623 , -2.6115074 ,  1.8690665 ,  2.0759716 ,  3.883594  ,\n",
       "       -2.2037592 , -1.6899511 ,  2.3061986 ,  3.1888757 , -1.9132993 ,\n",
       "        0.18676904, -0.5961214 , -1.3176379 ,  2.7311149 , -1.0665776 ,\n",
       "       -2.3821075 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector as a numpy array\n",
    "doc = nlp(\"I like cats\")\n",
    "# The L2 norm of the token's vector\n",
    "doc[2].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:52:59.630409Z",
     "iopub.status.busy": "2021-06-29T11:52:59.630121Z",
     "iopub.status.idle": "2021-06-29T11:52:59.639886Z",
     "shell.execute_reply": "2021-06-29T11:52:59.639161Z",
     "shell.execute_reply.started": "2021-06-29T11:52:59.63036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.784721"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].vector_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline components\n",
    "\n",
    "Functions that take a Doc object, modify it and return it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:03.445386Z",
     "iopub.status.busy": "2021-06-29T11:53:03.445102Z",
     "iopub.status.idle": "2021-06-29T11:53:03.767675Z",
     "shell.execute_reply": "2021-06-29T11:53:03.766729Z",
     "shell.execute_reply.started": "2021-06-29T11:53:03.445338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:05.184482Z",
     "iopub.status.busy": "2021-06-29T11:53:05.184206Z",
     "iopub.status.idle": "2021-06-29T11:53:05.189839Z",
     "shell.execute_reply": "2021-06-29T11:53:05.18909Z",
     "shell.execute_reply.started": "2021-06-29T11:53:05.184436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fd51c9d5940>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fd51c86a6a8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fd51c86a708>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:06.613323Z",
     "iopub.status.busy": "2021-06-29T11:53:06.613035Z",
     "iopub.status.idle": "2021-06-29T11:53:06.618133Z",
     "shell.execute_reply": "2021-06-29T11:53:06.616978Z",
     "shell.execute_reply.started": "2021-06-29T11:53:06.613276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that modifies the doc and returns it\n",
    "def custom_component(doc):\n",
    "    print(\"Do something to the doc here!\")\n",
    "    return doc\n",
    "\n",
    "# Add the component first in the pipeline\n",
    "nlp.add_pipe(custom_component, first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components can be added `first`, `last (default)`, or `before` or `after` an existing component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:08.52972Z",
     "iopub.status.busy": "2021-06-29T11:53:08.529418Z",
     "iopub.status.idle": "2021-06-29T11:53:08.549377Z",
     "shell.execute_reply": "2021-06-29T11:53:08.548231Z",
     "shell.execute_reply.started": "2021-06-29T11:53:08.529671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do something to the doc here!\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc, Token, Span\n",
    "doc = nlp(\"The sky over Guwahati is blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute extensions (with default value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:09.70922Z",
     "iopub.status.busy": "2021-06-29T11:53:09.708905Z",
     "iopub.status.idle": "2021-06-29T11:53:09.713852Z",
     "shell.execute_reply": "2021-06-29T11:53:09.712755Z",
     "shell.execute_reply.started": "2021-06-29T11:53:09.709173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register custom attribute on Token class\n",
    "Token.set_extension(\"is_color\", default=False)\n",
    "# Overwrite extension attribute with default value\n",
    "doc[5]._.is_color = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property extensions (with getter & setter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:10.877876Z",
     "iopub.status.busy": "2021-06-29T11:53:10.877595Z",
     "iopub.status.idle": "2021-06-29T11:53:10.884177Z",
     "shell.execute_reply": "2021-06-29T11:53:10.88334Z",
     "shell.execute_reply.started": "2021-06-29T11:53:10.87783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eulb si itahawuG revo yks ehT'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register custom attribute on Doc class\n",
    "get_reversed = lambda doc: doc.text[::-1]\n",
    "Doc.set_extension(\"reversed\", getter=get_reversed)\n",
    "# Compute value of extension attribute with getter\n",
    "doc._.reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method extensions (callable method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:12.03764Z",
     "iopub.status.busy": "2021-06-29T11:53:12.037295Z",
     "iopub.status.idle": "2021-06-29T11:53:12.044128Z",
     "shell.execute_reply": "2021-06-29T11:53:12.043092Z",
     "shell.execute_reply.started": "2021-06-29T11:53:12.037562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register custom attribute on Span class\n",
    "has_label = lambda span, label: span.label_ == label\n",
    "Span.set_extension(\"has_label\", method=has_label)\n",
    "# Compute value of extension attribute with method\n",
    "doc[3:5]._.has_label(\"GPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based matching\n",
    "## Using the Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:13.170115Z",
     "iopub.status.busy": "2021-06-29T11:53:13.169675Z",
     "iopub.status.idle": "2021-06-29T11:53:13.192571Z",
     "shell.execute_reply": "2021-06-29T11:53:13.191741Z",
     "shell.execute_reply.started": "2021-06-29T11:53:13.169913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do something to the doc here!\n",
      "New York\n"
     ]
    }
   ],
   "source": [
    "# Matcher is initialized with the shared vocab\n",
    "from spacy.matcher import Matcher\n",
    "# Each dict represents one token and its attributes\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add with ID, optional callback and pattern(s)\n",
    "pattern = [{\"LOWER\": \"new\"}, {\"LOWER\": \"york\"}]\n",
    "matcher.add('CITIES', None, pattern)\n",
    "# Match by calling the matcher on a Doc object\n",
    "doc = nlp(\"I live in New York\")\n",
    "matches = matcher(doc)\n",
    "# Matches are (match_id, start, end) tuples\n",
    "for match_id, start, end in matches:\n",
    "     # Get the matched span by slicing the Doc\n",
    "     span = doc[start:end]\n",
    "     print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:13.864887Z",
     "iopub.status.busy": "2021-06-29T11:53:13.864612Z",
     "iopub.status.idle": "2021-06-29T11:53:13.894172Z",
     "shell.execute_reply": "2021-06-29T11:53:13.893121Z",
     "shell.execute_reply.started": "2021-06-29T11:53:13.864842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do something to the doc here!\n",
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"After making the iOS update you won't notice a radical system-wide redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of iOS 11's furniture remains the same as in iOS 10. But you will discover some tweaks once you delve a little deeper.\")\n",
    "\n",
    "# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{'TEXT': 'iOS'}, {'IS_DIGIT': True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('IOS_VERSION_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:14.268051Z",
     "iopub.status.busy": "2021-06-29T11:53:14.26773Z",
     "iopub.status.idle": "2021-06-29T11:53:14.297343Z",
     "shell.execute_reply": "2021-06-29T11:53:14.296463Z",
     "shell.execute_reply.started": "2021-06-29T11:53:14.268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do something to the doc here!\n",
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{'LEMMA': 'download'}, {'POS': 'PROPN'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('DOWNLOAD_THINGS_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T11:53:14.787038Z",
     "iopub.status.busy": "2021-06-29T11:53:14.786732Z",
     "iopub.status.idle": "2021-06-29T11:53:14.812032Z",
     "shell.execute_reply": "2021-06-29T11:53:14.811369Z",
     "shell.execute_reply.started": "2021-06-29T11:53:14.786988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do something to the doc here!\n",
      "Total matches found: 4\n",
      "Match found: beautiful design\n",
      "Match found: smart search\n",
      "Match found: automatic labels\n",
      "Match found: optional voice responses\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Features of the app include a beautiful design, smart search, automatic labels and optional voice responses.\")\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN', 'OP': '?'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('ADJ_NOUN_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
